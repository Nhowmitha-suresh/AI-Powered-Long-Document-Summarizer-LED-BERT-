A single person claims to have authored 113 academic papers on artificial intelligence this year, 89 of which will be presented this week at one of the world’s leading conference on AI and machine learning, which has raised questions among computer scientists about the state of AI research.

The author, Kevin Zhu, recently finished a bachelor’s degree in computer science at the University of California, Berkeley, and now runs Algoverse, an AI research and mentoring company for high schoolers – many of whom are his co-authors on the papers. Zhu himself graduated from high school in 2018.

Papers he has put out in the past two years cover subjects like using AI to locate nomadic pastoralists in sub-Saharan Africa, to evaluate skin lesions, and to translate Indonesian dialects. On his LinkedIn, he touts publishing “100+ top conference papers in the past year”, which have been “cited by OpenAI, Microsoft, Google, Stanford, MIT, Oxford and more”.

Zhu’s papers are a “disaster”, said Hany Farid, a professor of computer science at Berkeley, in an interview. “I’m fairly convinced that the whole thing, top to bottom, is just vibe coding,” he said, referring to the practice of using AI to create software.

Farid called attention to Zhu’s prolific publications in a recent LinkedIn post, which provoked discussion of other, similar cases among AI researchers, who said their newly popular discipline faces a deluge of low-quality research papers, fueled by academic pressures and, in some cases, AI tools.

In response to a query from the Guardian, Zhu said that he had supervised the 131 papers, which were “team endeavors” run by his company, Algoverse. The company charges $3,325 to high-school students and undergraduates for a selective 12-week online mentoring experience – which involves help submitting work to conferences.

“At a minimum, I help review methodology and experimental design in proposals, and I read and comment on full paper drafts before submission,” he said, adding that projects on subjects such as linguistics, healthcare or education involved “principal investigators or mentors with relevant expertise”.

The teams used “standard productivity tools such as reference managers, spellcheck, and sometimes language models for copy-editing or improving clarity”, he said in response to a query about whether the papers were written with AI.